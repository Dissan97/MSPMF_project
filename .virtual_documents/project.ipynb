import sys
import os
import platform

   

sys.path.append(os.path.abspath(os.path.dirname('__file__')))
if platform.system() == "Windows":
    os.environ["R_HOME"] = r"C:\Program Files\R\R-4.4.2"
os.environ['R_LANGUAGE'] = 'en_US.UTF-8'
os.environ["PYTHONIOENCODING"] = "utf-8"
os.environ["R_DEFAULT_ENCODING"] = "utf-8"


%%capture
%pip install -q -r Requirements.txt


%%capture
%pip install --upgrade yfinance pandas_datareader requests


%%capture
"""
Al imports needed for this notebook
"""
#from model.names import IndexMeta as im
#from model.names import IndexMeta
import numpy as np
import pandas as pd
from pandas.tseries.offsets import BDay
from pathlib import Path
import yfinance as yf
from datetime import datetime, timedelta
import json
"""
    +----------------+
    | test libraries |
    +----------------+
"""
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.stats.diagnostic import het_arch, acorr_ljungbox
from scipy.stats import shapiro, normaltest, jarque_bera
import scipy.stats as stats
import statsmodels.api as sma
from scipy.stats import norm
from sklearn.metrics import mean_squared_error
"""
    +------------------+
    | graphics library |
    +------------------+
"""
from IPython.display import display, Markdown
import matplotlib.pyplot as plt
import seaborn as sns

import os
#from controller.injector import Injector
#from model.index import Index
import matplotlib.pyplot as plt
import json

"""
    +------------+
    | R packages |
    +------------+
"""
import rpy2.robjects.packages as rpackages
import rpy2.robjects as ro
from rpy2.robjects import pandas2ri


"""
    +-----------------+
    | Config defaults |
    +-----------------+
"""

class Config:
    LOOKUP_DAYS = 'lookup_days'
    END_DATE = 'end_date'
    DATE_FORMAT = 'date_format'
    INDEXES = 'indexes'
    LOCAL_CACHE = 'local_cache'
    LOCAL_CACHE_DIR = f'{os.getcwd()}{os.sep}local_cache'

"""
    +-------------------+
    | Metadata defaults |
    +-------------------+
"""
class IndexMeta:
    INDEX = 'index'
    DATE = 'Date'
    ADJ_CLOSE = 'Adj Close'
    ADJUSTED_CLOSE = 'Adjusted Close'
    LOG_RETURN = 'Log Return'
    LOG_RETURN_PERCENTAGE = 'Log Return Percentage'
    ABSOLUTE_RETURN = 'Absolute Return'
    SQUARED_RETURN = 'Squared Return'
    __ACF = 'ACF'
    ACF_LOG_RET = f'{__ACF} {LOG_RETURN}'
    ACF_ABS_RET = f'{__ACF} {ABSOLUTE_RETURN}'
    ACF_SQRT_RET = f'{__ACF} {SQUARED_RETURN}'
    REALIZED_VOLATILITY = 'Realized Volatility'
    ANNUALIZED_REALIZED_VOLATILITY = f'Annualized {REALIZED_VOLATILITY}'
    VOLATILITY_EWM = 'Volatility Ewm'
    ANNUALIZED_VOLATILITY_EWM = f'Annualized {VOLATILITY_EWM}'
    GARCH_RESIDUALS = 'Garch Residuals'
    GARCH_FORECAST_SERIES = 'Forecast Series'
    GARCH_FORECAST_SIGMA = 'Forecast Sigma'
    GARCH_CONDITIONAL_VOLATILITY = 'Garch Conditional Volatility'
    

    
"""
    +--------------+
    | Index Entity |
    +--------------+
"""
    
class Index:

    def __init__(self, index_name: str, index_ticker: str, data: pd.DataFrame):
        """

        :param index_name:
        :param index_ticker:
        :param data:
        :see da
        """
        self.i_name = index_name
        self.i_ticker = index_ticker
        self.df = data
        self.daily_info: pd.DataFrame = pd.DataFrame()
        self.realized_volatility: pd.DataFrame = pd.DataFrame()
        self.volatility_ewm: pd.DataFrame = pd.DataFrame()
        self.monthly_info: pd.DataFrame = pd.DataFrame()
        self.acf_log: pd.DataFrame = pd.DataFrame()
        self.acf_abs: pd.DataFrame = pd.DataFrame()
        self.acf_sqrt: pd.DataFrame = pd.DataFrame()
        self.residuals: pd.DataFrame = pd.DataFrame()
        self.forecast: pd.DataFrame = pd.DataFrame()
        self.model: str = ""

    def __str__(self):
        return f'{{name: {self.i_name}, ticker: {self.i_ticker}, data_size:{self.df.size}}}'

    def __repr__(self):
        return self.__str__()

    def get_df_by_name(self, col_name=IndexMeta.ADJUSTED_CLOSE) -> pd.DataFrame | None:

        if col_name in self.df.columns:
            return self.df[col_name]
        elif col_name in self.daily_info.columns:
            return self.daily_info[col_name]
        elif col_name in self.volatility_ewm.columns:
            return self.volatility_ewm[col_name]
        elif col_name in self.residuals.columns: 
            return self.residuals[col_name]
        elif col_name in self.realized_volatility:
            return self.realized_volatility[col_name]
        return None

    
"""
    +------------------------------+
    | Injecting data From yfinance |
    +------------------------------+
"""

class Injector:
    __DEFAULT_YEARS = 3
    __DEFAULT_LOOKUPS = __DEFAULT_YEARS * 365
    __DEFAULT_END = datetime.today()
    __DEFAULT_DATE_FORMAT = '%Y-%m-%d'
    __LINES = '-----------------------------------------------------------'

    def __init__(self, conf_file: str='', local=False):

        self.indexes: list[Index] = []
        if not local:
            self.__inject_data_from_yahoo(conf_file)
        else:
            #Todo sistemare il conf_file in modo da avere il referimento al cache locale
            self.load_local_cache(conf_file)
        self.__setup_daily_data()
        self.__setup_monthly_data()
        self.__setup_relized_volatility()
        self.__setup_volatility_ewm()
        self.__setup_index()
        pass

    def __inject_data_from_yahoo(self, conf_file):

        try:
            with open(conf_file, 'r', encoding='utf-8') as file_conf:
                config = json.load(file_conf)
                print(config)
                lookup_days = config.get(Config.LOOKUP_DAYS, Injector.__DEFAULT_LOOKUPS)
                end_date = config.get(Config.END_DATE, Injector.__DEFAULT_END)
                date_format = config.get(Config.DATE_FORMAT, Injector.__DEFAULT_DATE_FORMAT)
                start_date = (end_date - timedelta(days=lookup_days)).strftime(date_format)
                end_date = end_date.strftime(date_format)
                index_list = config.get(Config.INDEXES, None)
                for index in index_list:
                    from_yahoo = yf.download(
                        index_list[index],
                        start=start_date,
                        end=end_date,
                        auto_adjust=False
                    )
                    from_yahoo = pd.DataFrame({key[0]: value for key, value in from_yahoo.items()})
                    from_yahoo.reset_index(inplace=True)
                    from_yahoo.rename(columns={IndexMeta.INDEX: IndexMeta.DATE}, inplace=True)
                    from_yahoo.rename(columns={IndexMeta.ADJ_CLOSE: IndexMeta.ADJUSTED_CLOSE}, inplace=True)
                    from_yahoo[IndexMeta.DATE] = from_yahoo[IndexMeta.DATE].dt.date
                    index_bean = Index(index_name=index,
                                       index_ticker=index_list[index],
                                       data=from_yahoo)
                    #print(index_bean.df.columns)
                    self.indexes.append(index_bean)

        except FileNotFoundError:
            print(f"file {file_conf} not found")
            exit(-1)
        except json.JSONDecodeError:
            print("Error in decoding json")
            exit(-1)
        except AttributeError:
            print("some attribute is None")
            exit(-1)

    
    def load_local_cache(self, conf_file=''):
        directory = f'{Config.LOCAL_CACHE_DIR}'

        for filename in os.listdir(directory):
            file_path = os.path.join(directory, filename)
            if os.path.isfile(file_path):  
                pd.read_csv(file_path, sep=',', index_col="Date", parse_dates=True)
            pass
        
    
    def __setup_daily_data(self):

        for index in self.indexes:
            index.daily_info = pd.DataFrame(index.df[IndexMeta.DATE])

            index.daily_info[IndexMeta.LOG_RETURN] = np.log(
                index.df[IndexMeta.ADJUSTED_CLOSE] / index.df[IndexMeta.ADJUSTED_CLOSE].shift(1)
            )

            index.daily_info[IndexMeta.ABSOLUTE_RETURN] = index.df[IndexMeta.ADJUSTED_CLOSE].pct_change().abs()
            index.daily_info[IndexMeta.SQUARED_RETURN] = np.square(index.df[IndexMeta.ADJUSTED_CLOSE].pct_change())
            index.daily_info.set_index(IndexMeta.DATE, inplace=True)
            index.daily_info.index = pd.to_datetime(index.daily_info.index)
            index.daily_info.dropna(inplace=True)
            index.daily_info[IndexMeta.LOG_RETURN_PERCENTAGE] = index.daily_info[IndexMeta.LOG_RETURN] * 100

            # ACF for log return
            acf_values = sma.tsa.acf(index.daily_info[IndexMeta.LOG_RETURN], nlags=30)
            index.acf_log = pd.DataFrame({
                IndexMeta.ACF_LOG_RET: acf_values
            }, index=range(len(acf_values)))

            # ACF for absolute return
            acf_values = sma.tsa.acf(index.daily_info[IndexMeta.ABSOLUTE_RETURN], nlags=30)
            index.acf_abs = pd.DataFrame({
                IndexMeta.ACF_ABS_RET: acf_values
            }, index=range(len(acf_values)))
            # ACF for squared return
            acf_values = sma.tsa.acf(index.daily_info[IndexMeta.SQUARED_RETURN], nlags=30)
            index.acf_sqrt = pd.DataFrame({
                IndexMeta.ACF_SQRT_RET: acf_values
            }, index=range(len(acf_values)))

    def __setup_monthly_data(self):
        for index in self.indexes:
            dummy = pd.DataFrame(index.daily_info)
            dummy = dummy[dummy.index.is_month_end]
            index.monthly_info = dummy

        pass
    
    def __setup_relized_volatility(self, window=21):
        
        for index in self.indexes: 
            df = index.daily_info.copy()
            df[IndexMeta.REALIZED_VOLATILITY] = (df[IndexMeta.LOG_RETURN_PERCENTAGE].rolling(window=window).std()).dropna()
            df[IndexMeta.ANNUALIZED_REALIZED_VOLATILITY] = df[IndexMeta.REALIZED_VOLATILITY] * np.sqrt(252)
            #df.dropna(inplace=True)
            index.realized_volatility = df

    def __setup_volatility_ewm(self, lam=0.90) -> None:
        """
        :param lam: indicate the effort for older data
        """
        for index in self.indexes:
            dummy = pd.DataFrame(index.daily_info[[IndexMeta.LOG_RETURN_PERCENTAGE]])
            dummy_ewm = np.sqrt(dummy.ewm(span=1 / (1 - lam)).var())
            index.volatility_ewm = dummy_ewm
            index.volatility_ewm.columns = [IndexMeta.VOLATILITY_EWM]
            index.volatility_ewm[IndexMeta.ANNUALIZED_VOLATILITY_EWM] = (index.volatility_ewm[IndexMeta.VOLATILITY_EWM]
                                                                     * np.sqrt(252))

    def print_indexes(self):
        print(Injector.__LINES)
        print("Analyzing this index list: {")
        for index in self.indexes:
            print(f'\t{index}')
        print(f'}}\n{Injector.__LINES}')

    def get_multi_index(self) -> pd.DataFrame:
        ret: pd.DataFrame
        concat = []
        columns = []
        for index in self.indexes:
            concat.append(index.daily_info[IndexMeta.LOG_RETURN_PERCENTAGE])
            columns.append(index.i_name)
        ret = pd.concat(concat, axis=1)
        ret.columns = columns
        ret.dropna(inplace=True)
        return ret

    def local_cache(self):
        for index in self.indexes:
            name = index.i_name.replace(' ', '_')
            index.df.to_csv(f"{Config.LOCAL_CACHE}{os.sep}{name}-TimeSeries.csv")

    def __setup_index(self):
        for index in self.indexes:
            index.df.set_index('Date', inplace=True)

    def get_indexes_names(self) -> list[str]:
        ret = []
        for index in self.indexes:
            ret.append(index.i_name)
        return ret
    

            
              





%%capture
if not rpackages.isinstalled('rugarch') or not rpackages.isinstalled('rmgarch'):
    raise RuntimeError('rugarch missing')

injector = Injector(conf_file=f'{os.getcwd()}{os.sep}config{os.sep}config.json')


injector.local_cache()


"""
    +--------------------------+
    | Printers Plot and Tables |
    +--------------------------+
"""

class PlotColors:
    
    def __init__(self):
        raise NotImplemented('Cannot instantiate the class')
        
    __DEFAUL_COLORS = {
        "Blue": "#1976D2",
        "Red": "#D32F2F",
        "Green": "#388E3C",
        "Yellow": "#FBC02D",
        "Orange": "#E64A19",
        "Purple": "#7B1FA2",
        "Teal": "#00796B",
        "Pink": "#C2185B",
        "Turquoise": "#0097A7",
        "Gray": "#616161",
        "Brown": "#795548",
        "Cyan": "#00ACC1",
        "Lime": "#7CB342",
        "Magenta": "#D81B60",
        "Indigo": "#303F9F",
        "Gold": "#FFA000",
        "Crimson": "#C62828",
        "Olive": "#558B2F",
        "Navy": "#283593",
        "Amber": "#FF8F00",
        "Mint": "#4DB6AC"
    }
    
    @staticmethod
    def get_color(name='Blue'):
        return PlotColors.__DEFAUL_COLORS[name]
    
    @staticmethod
    def get_color_dict():
        return PlotColors.__DEFAUL_COLORS.copy()
    
    @staticmethod
    def get_color_list():
        color_list = []
        for (_, color) in PlotColors.__DEFAUL_COLORS.items():
            color_list.append(color)
        return color_list


def get_df_to_show(name, injector) -> pd.DataFrame():
    for index in injector.indexes:
        if index.i_name == name:
            return index.df
    return pd.DataFrame({})

def plot_adj_close(name, injector):
    plt.figure(figsize=(12, 6))
    df = get_df_to_show(name, injector)
    plt.plot(df.index, df[im.ADJUSTED_CLOSE])
    plt.show()


sns.set_theme(style="whitegrid")

def multi_plot_in_row(dfs: list[pd.DataFrame], info=IndexMeta.LOG_RETURN_PERCENTAGE,
                      fig_size=(20, 40), plot_names=None):
    if plot_names is None:
        plot_names = ["plot"]
    fig, axs = plt.subplots(len(dfs), 1, figsize=fig_size, gridspec_kw={'hspace': 0.75})
    i = 0
    for df in dfs:
        sns.lineplot(x=df.index, y=df[info], ax=axs[i], color='#2980b9')
        axs[i].set_title(f'{plot_names[i%len(plot_names)]} {info}')
        axs[i].set_xticks(axs[i].get_xticks())
        axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=45, ha='right')
        i+=1
    plt.show()


def print_res_test(data, test='adf') -> pd.DataFrame:
    ret = {}
    for index in data:
        ret[index] = {"Statistic": data[index][test][0] , 'PVALUE' : data[index][test][1], 'Null Hypotesis': data[index]['outcome']}
    return pd.DataFrame(ret)


from IPython.core.display import HTML

# Definire il CSS come stringa
css = """
    <head>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    </head>
    <style>
    /* Corpo della pagina */

    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background-color: #f7f9fc;
        color: #2c3e50;
        margin: 0;
        padding: 0;
        line-height: 1.6;
    }

    /* Contenitore principale */
    .container {
        width: 80%;
        margin: 0 auto;
        padding: 40px;
    }

    /* Titoli */
    h1 {
        font-size: 40px;
        text-align: center;
        color: #2980b9;
        margin-bottom: 20px;
    }

    h2 {
        font-size: 30px;
        color: #2980b9;
        margin-top: 40px;
        border-bottom: 2px solid #2980b9;
        padding-bottom: 10px;
    }

    h3 {
        font-size: 24px;
        color: #34495e;
        margin-top: 20px;
    }

    /* Paragrafi */
    p {
        font-size: 18px;
        color: #34495e;
        margin-bottom: 20px;
    }

    /* Liste */
    ul {
        list-style-type: square;
        margin-left: 30px;
        margin-bottom: 20px;
    }

    li {
        font-size: 18px;
        color: #34495e;
    }

    /* Evidenziazione */
    .highlight {
        color: #e74c3c;
        font-weight: bold;
    }

    /* Sezioni */
    .section {
        margin-bottom: 40px;
    }

    .content {
        background-color: #ffffff;
        padding: 30px;
        border-radius: 8px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        margin-top: 20px;
    }

    /* Link */
    a {
        color: #2980b9;
        text-decoration: none;
        font-weight: bold;
    }

    a:hover {
        text-decoration: underline;
    }

    /* Footer */
    footer {
        text-align: center;
        padding: 20px;
        background-color: #2c3e50;
        color: white;
        font-size: 16px;
        margin-top: 40px;
    }
    /* Stile della tabella */
    .styled-table {
        width: 70%;
        margin: 20px auto;
        border-collapse: collapse;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background-color: #ffffff;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        border-radius: 8px;
        border: 2px solid #2c3e50;  /* Bordo esterno più marcato */
    }

    /* Stile delle celle */
    .styled-table th, .styled-table td {
        border: 2px solid #2c3e50; /* Bordi più visibili */
        padding: 12px;
        text-align: center;
        font-size: 18px;
    }

    /* Colore intestazioni */
    .styled-table th {
        background-color: #2980b9;
        color: white;
        font-size: 20px;
        border: 2px solid #2c3e50;
    }

    /* Colore righe alternate */
    .styled-table tr:nth-child(even) {
        background-color: #f2f2f2;
    }

    /* Hover effetto */
    .styled-table tr:hover {
        background-color: #dfe6e9;
    }

    .styled-table-2 {
        width: 30%;
        height: 30%;
        margin: 20px auto;
        border-collapse: collapse;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background-color: #ffffff;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        border-radius: 8px;
        border: 2px solid #2c3e50;  /* Bordo esterno più marcato */
    }

    /* Stile delle celle */
    .styled-table-2 th, .styled-table-2 td {
        border: 2px solid #2c3e50; /* Bordi più visibili */
        padding: 12px;
        text-align: center;
        font-size: 14px;
    }

    /* Colore intestazioni */
    .styled-table-2 th {
        background-color: #2980b9;
        color: white;
        font-size: 16px;
        border: 2px solid #2c3e50;
    }

    /* Colore righe alternate */
    .styled-table-2 tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    
</style>


"""

# Visualizzare il CSS
HTML(css)



paragraph_1 = """<h1>Progetto di Metodi Probabilistici e Statistici per Mercati Finanziari</h1>
<h2>Autore: Dissan Uddin Ahmed</h2>

<div >
    <h2>Analisi Finanziaria Dei Mercati Nazionali</h2>
    <p>I mercati finanziari nazionali rappresentano un pilastro fondamentale dell’economia globale, riflettendo le dinamiche economiche, politiche e sociali di ciascun paese. Questo tipo di analisi aiuta gli investitori a gestire il rischio e capire quali titoli inserire nel proprio portafoglio finanziario. Si cerca di capire come la volatilità sia un parametro da tenere d'occhio quando si investe in borsa.</p>

    <div class="section">
        <h3>1) Analisi di mercato</h3>
        <p>La liquidità di un mercato finanziario si riferisce alla facilità con cui gli investitori possono comprare o vendere titoli finanziari senza causare significative fluttuazioni nei prezzi di mercato. Un mercato altamente liquido è caratterizzato da una maggiore attività di scambio di titoli, un elevato numero di partecipanti, un elevato volume di scambi giornalieri e una stretta differenza tra i prezzi di acquisto (offerta) e i prezzi di vendita (domanda), noti come spread.</p>
        <p>La liquidità è un importante fattore da considerare quando si decide di investire in un mercato finanziario.</p>
    </div>

    <div class="section">
        <h3>1.1) Entrata e Uscita mercato azionario</h3>
        <p>L'entrata e l'uscita dal mercato finanziario sono processi fondamentali per investitori e aziende. Un investitore entra nel mercato acquistando strumenti finanziari come azioni, obbligazioni o derivati, generalmente tramite un intermediario finanziario come una banca o un broker. La decisione di investire si basa su analisi di mercato e strategie di rendimento.</p>
        <p>Le aziende possono entrare nel mercato attraverso la quotazione in borsa (IPO), e uscire quando decidono di vendere i propri asset o quando non rispettano i requisiti di mercato.</p>
    </div>

    <div class="section">
        <h3>1.2) Liquidità del Mercato Azionario</h3>
        <p>La liquidità del mercato azionario si riferisce alla facilità con cui le azioni possono essere acquistate o vendute senza causare fluttuazioni significative nel loro prezzo. Ci sono due aspetti principali della liquidità:</p>
        <ul>
            <li><b>Liquidità immediata:</b> La capacità di eseguire ordini di acquisto o vendita a un prezzo vicino al valore di mercato senza influenzare il prezzo stesso.</li>
            <li><b>Profondità del mercato:</b> La quantità di ordini di acquisto e vendita a vari livelli di prezzo.</li>
        </ul>
        <p>Fattori che influenzano la liquidità includono il volume di scambi, la volatilità e la partecipazione degli investitori istituzionali.</p>
    </div>

    <div >
        <h2>2) Estrazione dei dati</h2>
        <p>Sono stati scelti i mercati nazionali più importanti e il mercato nazionale italiano, un mercato più piccolo, per verificare alla fine dello studio, se c'è correlazione tra queste borse. I dati sono stati scaricati tramite la libreria Python <code>yfinance</code>, e comprendono la serie storica degli ultimi due anni degli indici delle seguenti borse:</p>
        <ol>
            <li>FTSE MIB</li>
            <li>Dow Jones</li>
            <li>NASDAQ</li>
            <li>Nikkei 225</li>
            <li>HANG SENG INDEX</li>
        </ol>
    </div>
    <p>In questa sezione si osservano i dataset che sono stati presi in considerazione ed i prezzi di chiusura rettificata delle varie borse.</p>
</div>
"""
HTML(paragraph_1)





display(Markdown(get_df_to_show('FTSE MIB', injector).tail(10).to_html(classes='styled-table', escape=False)))








display(Markdown(get_df_to_show('London Stock Exchange', injector).tail(10).to_html(classes='styled-table', escape=False)))








display(Markdown(get_df_to_show('Dow Jones', injector).tail(10).to_html(classes='styled-table', escape=False)))








display(Markdown(get_df_to_show('NASDAQ', injector).tail(10).to_html(classes='styled-table', escape=False)))








display(Markdown(get_df_to_show('Nikkei 225', injector).tail(10).to_html(classes='styled-table', escape=False)))








display(Markdown(get_df_to_show('HANG SENG INDEX', injector).tail(10).to_html(classes='styled-table', escape=False)))








dfs_adj_closes = []
for index in injector.indexes:
    dfs_adj_closes.append(index.df)
multi_plot_in_row(dfs=dfs_adj_closes, plot_names=injector.get_indexes_names(), info=IndexMeta.ADJUSTED_CLOSE)





fig_2 = """
    <h3 id="fig_2">Grafico dei rendimenti logaritmici%</h3>
"""
display(HTML(fig_2))


dfs_log_ret = []
for index in injector.indexes:
    dfs_log_ret.append(index.daily_info)
multi_plot_in_row(dfs=dfs_log_ret, plot_names=injector.get_indexes_names())








P_VALUE = 0.05
"""
 Value for what test is passed or not
"""


def adfuller_test(indexes, target=IndexMeta.ADJUSTED_CLOSE):
    """
        :param indexes: List 
        :param target: column to target of the dataset
    """
    
    res = {}
    for index in indexes: 
        df_target = None
        name = ""
        if isinstance(index, Index):
            df_target = index.get_df_by_name(target)
            name = index.i_name
        else:
            df_target = indexes[index]['DataSet'][target]
            name = index
        adf_res = adfuller(df_target)
        res[name] = {
            'adf' : adf_res,
            'parameter': target
        }
        res[name]['outcome'] = f'{"accepted" if res[name]["adf"][1] > P_VALUE else "rejected"}'
    return res

def kpss_test(indexes, target=IndexMeta.ADJUSTED_CLOSE):
    res = {}
    for index in indexes: 
        df_target = None
        name = ""
        if isinstance(index, Index):
            df_target = index.get_df_by_name(target)
            name = index.i_name
        else:
            df_target = indexes[index]['DataSet'][target]
            name = index
        kpss_res = kpss(df_target)
        res[name] = {
            'kpss' : kpss_res,
            'parameter': target
        }
        res[name]['outcome'] = f'{"accepted" if res[name]["kpss"][1] > P_VALUE else "rejected"}'
    return res

def het_arch_test(indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE):
    res = {}

    for index in indexes: 
        df_target = (index.get_df_by_name(target).rolling(window=21).std() * np.sqrt(252)).dropna()
        het_arch_res = het_arch(df_target)
        res[index.i_name] = {
            'engles arch' : het_arch_res,
            'parameter': target
        }
        res[index.i_name]['outcome'] = f'{"accepted" if res[index.i_name]["engles arch"][1] > P_VALUE else "rejected"}'
    return res

def ljung_box_test(indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE, squared=False, lags=10):
    res = {}

    for index in indexes:
        df_target = None
        name = ""
        if isinstance(index, Index):
            df_target = index.get_df_by_name(target)
            name = index.i_name
        else:
            if squared:
                df_target = indexes[index]['DataSet'][target] ** 2
            else: 
                df_target = indexes[index]['DataSet'][target]
            name = index
        ljb_res = acorr_ljungbox(df_target, model_df=2, lags=[lags], return_df=True)
        ljb_local = (ljb_res.at[lags,"lb_stat"], ljb_res.at[lags,"lb_pvalue"])
        res[name] = {
            'ljung box' : ljb_local,
            'parameter': target
        }
        res[name]['outcome'] = f'{"accepted" if res[name]["ljung box"][1] > P_VALUE else "rejected"}'
    return res        


adjusted_closes_adf = adfuller_test(indexes=injector.indexes, target=IndexMeta.ADJUSTED_CLOSE)
log_ret_perc_adf = adfuller_test(indexes=injector.indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE)



tab_1 = """
<h4 id="tab_1">Test ADF Chiusura Rettificata</h4>
<p>Qui si fa il test sui Prezzi rettificati ci si aspetta che l'ipotesi nulla sia accettata. I prezzi generalmente non sono stazionari.</p>
"""
display(HTML(tab_1))


adjusted_closes_adf_table = print_res_test(adjusted_closes_adf).T.to_html(classes='styled-table-2', escape=False)
adjusted_closes_adf_table = """
<h4 id="tab_1">Test ADF Chiusura Rettificata</h4>
<p>Qui si fa il test sui Prezzi rettificati ci si aspetta che l'ipotesi nulla sia accettata. I prezzi generalmente non sono stazionari.</p>
""" + adjusted_closes_adf_table
display(Markdown(adjusted_closes_adf_table))





tab_2 = """
<h4 id="tab_2">Test ADF Ritorno logaritmico in percentuale</h4>
<p>Nei dati di mercato si aspetta che i rendimenti logaritmici siano stazionari quindi, il test rigetta l'ipotesi nulla che non siano stazionari.</p>
"""
display(HTML(tab_2))


from IPython.display import display, Markdown
log_ret_perc_adf_table = print_res_test(log_ret_perc_adf).T.to_html(classes='styled-table-2', escape=False)
display(Markdown(log_ret_perc_adf_table))








tab_3 = """
    <h4 id="tab_3">Test Kpss chiusura Rettificata</h4>
    <p>Ci si aspetta di rifiutare l'ipotesi nulla del test KPSS, che assume la stazionarietà della serie delle chiusure rettificate dei prezzi.<br>
    Questo risultato è coerente con il test ADF, che indica che i prezzi non sono stazionari<a href="#tab_1">[Tabella 1]</a>.</p>
"""
display(HTML(tab_3))



%%capture
adjusted_closes_kpss = kpss_test(indexes=injector.indexes, target=IndexMeta.ADJUSTED_CLOSE)
log_ret_perc_kpss = kpss_test(indexes=injector.indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE)


adjusted_closes_kpss_table = print_res_test(adjusted_closes_kpss, test='kpss').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(adjusted_closes_kpss_table))





tab_4 = """
    <h4 id="tab_4">Test Kpss Ritorno logarimico</h4>
    <p>Ci si aspetta che l'ipotesi nulla venga accettata in quanto in <a href="#tab_2">[Tabella 2]</a>, viene rifiutato il test ADF</p>
"""
display(HTML(tab_4))


log_ret_perc_kpss_table = print_res_test(log_ret_perc_kpss, test='kpss').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(log_ret_perc_kpss_table))








tab_5 = """
    <h4 id="tab_5">Test Engle's Arch Ritorno sulla volatilià</h4>
    <p>Si decidere di prendere in considerazione i rendimenti logaritmici e si testa la volatilità realizzata su una finestra mobile di 21 giorni</p>
"""
display(HTML(tab_5))



log_ret_perc_het_arch = het_arch_test(indexes=injector.indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE)


log_ret_perc_het_arch_table = print_res_test(log_ret_perc_het_arch, test='engles arch').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(log_ret_perc_het_arch_table))








fig_3 = """
    <h3 id="fig_4">3.5) Plot delle volatilità Realizzate Annualizzate</h3>
"""
display(HTML(fig_3))


volatilities_annualized = []
for index in injector.indexes: 
    volatilities_annualized.append(index.realized_volatility)
multi_plot_in_row(dfs=volatilities_annualized, plot_names=injector.get_indexes_names(), info=IndexMeta.ANNUALIZED_REALIZED_VOLATILITY)








def shapiro_test(indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE):
    res = {}
    for index in indexes: 
        df_target = index.get_df_by_name(target)
        shapiro_res = shapiro(df_target)
        res[index.i_name] = {
            'shapiro' : shapiro_res,
            'parameter': target
        }
        res[index.i_name]['outcome'] = f'{"accepted" if res[index.i_name]["shapiro"].pvalue > P_VALUE else "rejected"}'
    return res


def agostino_person_test(indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE):
    res = {}
    for index in indexes: 
        df_target = index.get_df_by_name(target)
        normaltest_res = normaltest(df_target)
        res[index.i_name] = {
            'agostino-person' : normaltest_res,
            'parameter': target
        }
        res[index.i_name]['outcome'] = f'{"accepted" if res[index.i_name]["agostino-person"].pvalue > P_VALUE else "rejected"}'
    return res

def jarque_bera_test (indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE):
    res = {}
    for index in indexes: 
        df_target = index.get_df_by_name(target)
        jarque_bera_res = jarque_bera(df_target)
        res[index.i_name] = {
            'jarque-bera' : jarque_bera_res,
            'parameter': target
        }
        res[index.i_name]['outcome'] = f'{"accepted" if res[index.i_name]["jarque-bera"].pvalue > P_VALUE else "rejected"}'
    return res



log_ret_perc_shapiro = shapiro_test(indexes=injector.indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE)


tab_6 = """
    <h4 id="tab_6">Shapiro Test Sui rendimenti Logaritmici</h4>
"""
display(HTML(tab_6))


log_ret_perc_shapiro_table = print_res_test(log_ret_perc_shapiro, test='shapiro').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(log_ret_perc_shapiro_table))





log_ret_perc_agostino_pearson = agostino_person_test(indexes=injector.indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE)  


tab_7 = """
    <h4 id="tab_7">Agostino Pearson Test sui Rendimenti Logaritmici</h4>
"""
display(HTML(tab_7))


log_ret_perc_agostino_pearson_table = print_res_test(log_ret_perc_agostino_pearson, test='agostino-person').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(log_ret_perc_agostino_pearson_table))





log_ret_perc_jarque_bera = jarque_bera_test(indexes=injector.indexes, target=IndexMeta.LOG_RETURN_PERCENTAGE)  


tab_8 = """
    <h4 id="tab_8">Jarque Bera Test sui Rendimenti Logaritmici</h4>
"""
display(HTML(tab_8))


from IPython.display import display, Markdown
log_ret_perc_jarque_bera_table = print_res_test(log_ret_perc_jarque_bera, test='jarque-bera').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(log_ret_perc_jarque_bera_table))





qq_plots = """
    <h3 id = "qq-plots-1">3.6) QQ-Plot</h3>
    <p>Il QQ-Plot (Quantile-Quantile Plot) è uno strumento grafico utilizzato per confrontare la distribuzione dei dati osservati con una distribuzione teorica di riferimento,
    ad esempio la distribuzione normale.<br> Se i punti del QQ-Plot si allineano lungo una retta, ciò indica che la distribuzione dei dati è simile a quella teorica.<br>
    In caso contrario, eventuali deviazioni dalla retta possono segnalare asimmetria, code pesanti o altre anomalie nella distribuzione.</p>
"""
display(HTML(qq_plots))


def show_qq():
    x = 0
    if len(injector.indexes) % 2 != 0:
        x = 1

    fig, axs = plt.subplots(int(len(injector.indexes) / 2) + x, 2, figsize=(20,30))
    i = 0
    j = 0
    for index in injector.indexes:
        stats.probplot(index.daily_info[IndexMeta.LOG_RETURN_PERCENTAGE], dist="norm", plot=axs[i][j])
        axs[i][j].set_title(f'QQ-PLOT {index.i_name}')
        j += 1
        if j % 2 == 0:
            j = 0
            i+=1

    plt.show()
show_qq()





class GarchUtil:
    
    def __init__(self, indexes: list[Index] = None, col=IndexMeta.LOG_RETURN_PERCENTAGE, split=0.9):
        self.indexes: list[Index] = indexes
        self.col = col
        self.trains = {}
        self.tests = {}
        if indexes is None:
            self.indexes = []
        
        self.make_train_and_test(split=split)
    
    def make_train_and_test(self, split=0.9):
        self.trains: list[pd.DataFrame] = {}
        self.tests: list[pd.DataFrame] = {}
        for index in self.indexes:
            df = index.get_df_by_name(self.col)
            cut = int(len(df)*split)
            self.trains[index.i_name] = pd.DataFrame(df.iloc[:cut])
            self.tests[index.i_name] = pd.DataFrame(df.iloc[cut:])
    
    def get_index_by_name(self, name) -> Index:
        for index in self.indexes:
            if name == index.i_name:
                return index
        return None

def r2py_array_to_list (array) -> list:
    ret = []
    for element in array:
        ret.append(element[0])
    return ret


"""
    +------------+
    | FGARCH-FIT |
    +------------+------------------+
    | Check file in R/Garch_model.R |
    +-------------------------------+
"""


def gen_trajectories(garch_util: GarchUtil, num_sims=200):
    trajectories = []
    
    

def ru_garch_in_R(garch_util: GarchUtil, num_sims=200):
    indexes = garch_util.indexes
    if indexes is None:
        return
    pandas2ri.activate()
    ro.r('Sys.getlocale()')
    ro.r('Sys.setlocale("LC_ALL", "en_US.UTF-8")')
    ro.r('source("R/Garch_model.R")')
    get_garch_best_models = ro.r['get_garch_best_models']
    garch_model_infos = {}
    
    trains = garch_util.trains
    tests = garch_util.tests
    for index in indexes:
        name = index.i_name
        ret = trains[name]
        forecast_horizon = len(tests[name])
        r_ret = ro.conversion.py2rpy(ret)
        r_fh = ro.conversion.py2rpy(forecast_horizon)
        r_func_ret = get_garch_best_models(r_ret, forecast_horizon)
        df_res = ret.copy()
        df_res[IndexMeta.GARCH_RESIDUALS] = ro.conversion.rpy2py(r_func_ret[3])
        df_res.drop(columns=[IndexMeta.LOG_RETURN_PERCENTAGE], inplace=True)
        index.residuals = df_res
        
        # Generating dataframe for Forecast
        sigma = r2py_array_to_list(ro.conversion.rpy2py(r_func_ret[4]))
        series = r2py_array_to_list(ro.conversion.rpy2py(r_func_ret[5]))
        T_0 = tests[name].head().index[0]
        #dates = pd.date_range(start=T_0, periods=forecast_horizon, freq='B')

        # dataframe for the forecast
        forecast_df = pd.DataFrame(
            {
                IndexMeta.GARCH_FORECAST_SERIES : series,
                IndexMeta.GARCH_FORECAST_SIGMA : sigma
            }, index=tests[name].index
        )

        index.forecast = forecast_df
        index.model = {
            'fGARCH[GARCH(1,1)]' : {
                "index": name,
                "dist": str(r_func_ret[0][0]),
                "information_criteria": {
                    "shibata": float(r_func_ret[1][0]),
                },
                IndexMeta.GARCH_CONDITIONAL_VOLATILITY: pd.DataFrame({IndexMeta.GARCH_CONDITIONAL_VOLATILITY: ro.conversion.rpy2py(r_func_ret[2]).flatten()},
                                                                     index = trains[name].index),
                "params": {
                    "omega": float(r_func_ret[6][0]),
                    "alpha1": float(r_func_ret[7][0]),
                    "beta1": float(r_func_ret[8][0])
                }
            }
        }
        

    pandas2ri.deactivate()


%%capture
garch_util = GarchUtil(injector.indexes)
ru_garch_in_R(garch_util=garch_util)





%%capture
residual_adf = adfuller_test(indexes=injector.indexes, target=IndexMeta.GARCH_RESIDUALS)


tab_9 = """
<h4 id="tab_9">Test ADF Sui residui del modello GARHC</h4>
<p>Nei dati di mercato si aspetta che i residui siano stazionari quindi, il test rigetta l'ipotesi nulla che non siano stazionari.<br>
Come in <a href="#tab_2">[Tabella 2]
</p>
"""
display(HTML(tab_9))


residual_adf_table = print_res_test(residual_adf, test='adf').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(residual_adf_table))





%%capture
residuals_kpss = kpss_test(indexes=injector.indexes, target=IndexMeta.GARCH_RESIDUALS)


tab_10 = """
    <h4 id="tab_4">Test Kpss Residui modello GARCH</h4>
    <p>Ci si aspetta che l'ipotesi nulla venga accettata in quanto ci si aspetta che i residui siano stazionari.<br>
    Come in <a href="#tab_4">[Tabella 4].</a></p>
"""
display(HTML(tab_10))


residuals_kpss_table = print_res_test(residuals_kpss, test='kpss').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(residuals_kpss_table))





residuals_ljung_box = ljung_box_test(indexes=injector.indexes, target=IndexMeta.GARCH_RESIDUALS)


tab_11 = """
    <h4 id="tab_11">Test Ljung-Box Residui modello GARCH</h4>
    <p>Ci si aspetta che l'ipotesi nulla venga accettata, indicando che i residui non presentano autocorrelazione e seguono un rumore bianco.<br>
"""

display(HTML(tab_11))


residuals_ljung_box_table = print_res_test(residuals_ljung_box, test='ljung box').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(residuals_ljung_box_table))





residuals_ljung_box_sq = ljung_box_test(indexes=injector.indexes, target=IndexMeta.GARCH_RESIDUALS, squared=True)



tab_12 = """
    <h4 id="tab_12">Test Ljung-Box Residui Quadri modello f-GARCH</h4>
    <p>Ci si aspetta che l'ipotesi nulla venga accettata, indicando che i residui non presentano autocorrelazione e seguono un rumore bianco.<br>
"""

display(HTML(tab_12))


residuals_ljung_box_sq_table = print_res_test(residuals_ljung_box_sq, test='ljung box').T.to_html(classes='styled-table-2', escape=False)
display(Markdown(residuals_ljung_box_table))








def residuals_scatter_plot(garch_util: GarchUtil, fig_size=(20, 25)):
    if garch_util is None:
        print('No GarchUtil provided')
        return 
    indexes = garch_util.indexes
    if indexes is None:
        print('No indexes found in GarchUtil')
        return

    colors = PlotColors.get_color_list()
    
    fig, axs = plt.subplots(len(indexes), 1, figsize=fig_size, gridspec_kw={'hspace': 0.6})

    for i, index in enumerate(indexes):
        residuals = index.residuals[IndexMeta.GARCH_RESIDUALS]
        time_index = residuals.index

        sns.scatterplot(x=time_index, y=residuals, color=colors[i % len(colors)], label=index.i_name, alpha=0.6, ax=axs[i])
        axs[i].set_title(f'Residui per {index.i_name}', fontsize=14)
        axs[i].set_ylabel(IndexMeta.LOG_RETURN_PERCENTAGE)
        axs[i].set_xlabel("Date", fontsize=12)
        axs[i].set_xticks(axs[i].get_xticks())
        axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=45, ha='right')
        #axs[i].legend(loc="lower center", bbox_to_anchor=(0.5, -0.7), ncol=3, frameon=True)
    plt.xticks(rotation=45)
    plt.show()


residuals_scatter_plot(garch_util)





import statsmodels.api as sm

def show_autocorr(garch_util: GarchUtil, lags=21):
    
    fig, ax = plt.subplots(len(garch_util.indexes), 1,figsize=(20, 30))
    for i, index in enumerate(garch_util.indexes):
        sm.graphics.tsa.plot_acf(index.get_df_by_name(IndexMeta.GARCH_RESIDUALS), lags=lags, title=f'{index.i_name} Autocorrelation', ax=ax[i])
    plt.show()


show_autocorr(garch_util=garch_util, lags=21)





def gen_trajectories(garch_util, n_simulations=1000, seed=20232024):
    indexes = garch_util.indexes
    trajectories = {}
    median_trajectories = {}

    np.random.seed(seed)

    for index in indexes:
        name = index.i_name
        params = index.model['fGARCH[GARCH(1,1)]']['params']
        omega, alpha, beta = params['omega'], params['alpha1'], params['beta1']
        horizon = len(garch_util.tests[name].index)

        simulated_returns = np.zeros((horizon, n_simulations))
        last_sigma2 = float(index.model['fGARCH[GARCH(1,1)]'][IndexMeta.GARCH_CONDITIONAL_VOLATILITY].mean().iloc[0]) ** 2

        for sim in range(n_simulations):
            sigma2 = last_sigma2  
            for t in range(horizon):
                epsilon = np.random.normal(0, 1)  
                simulated_returns[t, sim] = np.sqrt(sigma2) * epsilon
                sigma2 = omega + (alpha * (simulated_returns[t, sim] ** 2)) + (beta * sigma2)

        df = pd.DataFrame(simulated_returns, index=garch_util.tests[name].index)
        
        trajectories[name] = {
            "simulated" : df,
            "mean" : pd.DataFrame(df.T.mean()),
        }

    return trajectories



def plot_garch_trajectories(trajectories, garch_util, n_samples=100):
    num_plots = len(trajectories)
    fig, axs = plt.subplots(num_plots, 1, figsize=(20, 7 * num_plots), gridspec_kw={'hspace': 0.6})
        
    if num_plots == 1:
        axs = [axs]  
    
    for i, (k, v) in enumerate(trajectories.items()):
        df_sim = v['simulated']
        df_test = garch_util.tests[k]
        axs[i].plot(df_sim.index, df_sim.iloc[:, :n_samples], color="blue", alpha=0.1, linewidth=0.8)
        median_series = df_sim.median(axis=1)
        axs[i].plot(df_sim.index, median_series, color="red", linewidth=2, label="Mediana Simulazioni")
        #axs[i].plot(df_test.index, df_test, color="black", linewidth=2, linestyle="dashed", label="Dati Reali")
        #axs[i].axhline(y=df_test.mean(), linestyle="dashed", color="black", label="real mean")
        axs[i].set_title(f'Rendimenti simulati per {k}', fontsize=14)
        axs[i].set_ylabel(IndexMeta.LOG_RETURN_PERCENTAGE)
        axs[i].set_xlabel("Date", fontsize=12)
        axs[i].set_xticks(axs[i].get_xticks())
        axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=45, ha='right')
        axs[i].legend(loc="lower center", bbox_to_anchor=(0.5, -0.7), ncol=3, frameon=True)

    
    
    plt.show()



trajectories = gen_trajectories(garch_util=garch_util)


plot_garch_trajectories(trajectories=trajectories, garch_util=garch_util)





def volatility_comparison(garch_util: GarchUtil, conf_levels=None, fig_size=(20,45)):
    
    colors = PlotColors.get_color_list()
    if garch_util is None:
        print('no garch util provied')
        return 
    indexes = garch_util.indexes
    if indexes is None:
        print('not indexes found in garch util')
        return
    
    num_plots = len(indexes)
    fig, axs = plt.subplots(num_plots, 1, figsize=(20, 7 * num_plots), gridspec_kw={'hspace': 0.6})
    i = 0
    trains = garch_util.trains
    for index in indexes:
        j=0
        first = True
        IndexMeta.GARCH_CONDITIONAL_VOLATILITY
        sns.lineplot(x=trains[index.i_name].index, y=trains[index.i_name][IndexMeta.LOG_RETURN_PERCENTAGE], ax=axs[i], color='black',
                     label=f'{IndexMeta.LOG_RETURN_PERCENTAGE}', alpha=0.5)
        sns.lineplot(x=trains[index.i_name].index, y=index.realized_volatility[IndexMeta.REALIZED_VOLATILITY].iloc[0:len(trains[index.i_name])],
                     ax=axs[i], color=colors[0], label=f'{IndexMeta.REALIZED_VOLATILITY}', linewidth=2)
        sns.lineplot(x=index.model['fGARCH[GARCH(1,1)]']['Garch Conditional Volatility'].index,
                     y=index.model['fGARCH[GARCH(1,1)]']['Garch Conditional Volatility'][IndexMeta.GARCH_CONDITIONAL_VOLATILITY],
                     ax=axs[i], color=colors[1], label=f'{IndexMeta.GARCH_CONDITIONAL_VOLATILITY}',
                     linewidth=2, linestyle="dashed")
        axs[i].set_title(label=f'{index.i_name} Volatility and {IndexMeta.LOG_RETURN_PERCENTAGE}')        
        axs[i].set_xticks(axs[i].get_xticks())
        axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=45, ha='right')
        axs[i].legend(loc="lower center", bbox_to_anchor=(0.5, -0.4), ncol=3, frameon=True)
        
        
        i += 1
    plt.xticks(rotation=45)
    plt.show()





volatility_comparison(garch_util)





def get_confidence_intervals(indexes=None, conf_levels=None):
    if indexes is None:
        return pd.DataFrame()
    if conf_levels is None:
        conf_levels = [0.8, 0.85, 0.9, 0.95]

    ks = [norm.ppf(1 - (1 - conf) / 2) for conf in conf_levels]
    results = {}

    for index in indexes:
        results[index.i_name] = {}
        actual_returns = index.daily_info[IndexMeta.LOG_RETURN_PERCENTAGE].reindex(index.forecast.index).dropna()

        for k, conf_level in zip(ks, conf_levels):
            upper_band = k * index.forecast[IndexMeta.GARCH_FORECAST_SIGMA]
            lower_band = -k * index.forecast[IndexMeta.GARCH_FORECAST_SIGMA]

            inside_band = ((actual_returns >= lower_band) & (actual_returns <= upper_band)).sum()
            total_points = len(actual_returns)
            percentage_inside = round((inside_band / total_points) * 100, 2) if total_points > 0 else 0.00

            results[index.i_name][f"{int(conf_level * 100)}%"] = f"{percentage_inside:.2f}%"

    return pd.DataFrame.from_dict(results, orient='index')

def plot_prevision_band(indexes=None, conf_levels=None, fig_size=(20,45)):
    colors = PlotColors.get_color_list()
    if indexes is None:
        return
    if conf_levels is None:
        conf_levels = [0.8, 0.9, 0.95]
        #conf_levels.sort(reverse=True)
    
    fig, axs = plt.subplots(len(indexes), 1, figsize=fig_size,  gridspec_kw={'hspace': 0.8})
    
    
    ks = []
    for conf_level in conf_levels:
        alpha = 1 - conf_level
        ks.append(norm.ppf(1 - alpha / 2))
    
    i = 0
    for index in indexes:
        j=0
        first = True
        sns.lineplot(x=index.daily_info.index, y=index.daily_info[IndexMeta.LOG_RETURN_PERCENTAGE], ax=axs[i], color=colors[0],
                     label=f'{index.i_name} {IndexMeta.LOG_RETURN_PERCENTAGE}')
        axs[i].set_title(label=f'{index.i_name} prediction bands')
        for k in ks:sudo apt update && sudo apt install libstdc++6
            upper_band = (k * pd.DataFrame(index.forecast[IndexMeta.GARCH_FORECAST_SIGMA]))
            lower_band = (-k * pd.DataFrame(index.forecast[IndexMeta.GARCH_FORECAST_SIGMA]))
            if first:
                first = False
                axs[i].axvline(x=upper_band.index[0], linestyle="dashed", color="black", label="test set boundary")
            axs[i].fill_between(index.forecast.index,upper_band[IndexMeta.GARCH_FORECAST_SIGMA],
                                lower_band[IndexMeta.GARCH_FORECAST_SIGMA], alpha=0.3,color=colors[j+1])
            sns.lineplot(x=index.forecast.index, y=upper_band[IndexMeta.GARCH_FORECAST_SIGMA], linestyle="dashed", ax=axs[i],  color=colors[j+1],
                         label=f'UpperBound {int(conf_levels[j] * 100)}%')
            sns.lineplot(x=index.forecast.index, y= lower_band[IndexMeta.GARCH_FORECAST_SIGMA], linestyle="dashed", ax=axs[i],  color=colors[j+1],
                         label=f'LowerBound {int(conf_levels[j] * 100)}%')
            j +=1
        axs[i].set_xticks(axs[i].get_xticks())
        axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=45, ha='right')
        axs[i].legend(loc="lower center", bbox_to_anchor=(0.5, -0.6), ncol=3, frameon=True)
        
        
        
        i += 1
    #plt.xticks(rotation=45)
    plt.show()
    




df = plot_prevision_band(injector.indexes)


display(HTML(get_confidence_intervals(injector.indexes).to_html(classes='styled-table-2', escape=False)))





def mae(y_true, y_pred):
    return np.mean(np.abs(y_true - y_pred))

def mse(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

def mase(y_true, y_pred):
    mae_val = mae(y_true, y_pred)
    naive_mae = np.mean(np.abs(np.diff(y_true)))  
    return mae_val / naive_mae if naive_mae != 0 else np.nan  

def rmsse(y_true, y_pred):
    mse_val = mse(y_true, y_pred)
    naive_mse = np.mean(np.diff(y_true) ** 2)  
    return np.sqrt(mse_val / naive_mse) if naive_mse != 0 else np.nan  

def make_accuracy_dict() -> dict:
    accuracy_dict = {}
    for index in garch_util.indexes:
        MSE = mse(index.realized_volatility.tail(len(index.forecast))[IndexMeta.REALIZED_VOLATILITY],
                  (index.forecast[IndexMeta.GARCH_FORECAST_SIGMA])**2)
        MAE = mae(index.realized_volatility.tail(len(index.forecast))[IndexMeta.REALIZED_VOLATILITY],
                  (index.forecast[IndexMeta.GARCH_FORECAST_SIGMA])**2)
        MASE = mase(index.realized_volatility.tail(len(index.forecast))[IndexMeta.REALIZED_VOLATILITY],
                  (index.forecast[IndexMeta.GARCH_FORECAST_SIGMA])**2)
        RMSSE = rmsse(index.realized_volatility.tail(len(index.forecast))[IndexMeta.REALIZED_VOLATILITY],
                  (index.forecast[IndexMeta.GARCH_FORECAST_SIGMA])**2)
        accuracy_dict[index.i_name] = {
            'MAE' : MAE,
            'MSE' : MSE,
            'MASE': MASE,
            'RMSSE': RMSSE
        }
    return pd.DataFrame.from_dict(accuracy_dict, orient='index')


display(HTML(make_accuracy_dict().to_html(classes='styled-table-2', escape=False)))





def plot_dataframe_lines(df, title='Grafi dei Rendimenti', figsize=(20, 10), colors=None):
    plt.figure(figsize=figsize)
    
    if colors is None:
        colors = PlotColors.get_color_list()
        
    for i, column in enumerate(df.columns):
        sns.lineplot(x=df.index, y=df[column], label=column, color=colors[i], linewidth=1)

    plt.title(title, fontsize=14, fontweight="bold")
    plt.xlabel("Date", fontsize=12)
    plt.ylabel(IndexMeta.LOG_RETURN_PERCENTAGE, fontsize=12)
    plt.xticks(rotation=45)
    plt.legend(title="Indici", bbox_to_anchor=(1.05, 1), loc="upper left", fontsize=10)
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.show()


plot_dataframe_lines(injector.get_multi_index())





AVAILABLE_RM_GARCH = {
    "DCC": "get_best_dcc_garch",
    "GO" : "get_best_go_garch",
    "CDCC": "get_best_cdcc_garch"
}

def rm_garch_in_R(rm_model=AVAILABLE_RM_GARCH["DCC"]):
    
    ret = []
    forecast_horizon = 5
    pandas2ri.activate()
    ro.r('Sys.getlocale()')
    ro.r('Sys.setlocale("LC_ALL", "en_US.UTF-8")')
    ro.r('source("R/RMGarch_model.R")')
    df_log_ret = injector.get_multi_index()
    model_r_func = ro.r[f'{rm_model}']
    r_rets = ro.conversion.py2rpy(df_log_ret)
    r_rets = ro.r('as.matrix')(r_rets) 
    r_rmgarch = ro.r(rm_model)
    r_res = r_rmgarch(r_rets, 20)
    r_dccgarch_model = r_res[0]
    r_forecast_cov = r_res[1]
    pandas2ri.deactivate()
    n_cols = df_log_ret.shape[1]
    n_elements = n_cols * n_cols
    n_matrix = len(r_forecast_cov[0]) // n_elements

    cov_matrix = np.zeros((n_cols, n_cols))
    for i in range(n_matrix):
        i_matrix = np.array(r_forecast_cov[0][i * n_elements:(i + 1) * n_elements])
        i_matrix = i_matrix.reshape(n_cols, n_cols)
        cov_matrix += i_matrix

    print("Numero di matrici previste:", n_matrix)
    print("Matrice di covarianza sommata:\n", cov_matrix)
    corr_matrix = np.corrcoef(cov_matrix)
    return corr_matrix
    
#rm_garch_in_R(indexes=[], rm_model=AVAILABLE_RM_GARCH['DCC'])
#rm_garch_in_R(indexes=[], rm_model=AVAILABLE_RM_GARCH['GO'])
#rm_garch_in_R(indexes=[], rm_model=AVAILABLE_RM_GARCH['CDCC'])






labels = []
for index in injector.indexes:
    labels.append(index.i_name)
sns.heatmap(rm_garch_in_R(AVAILABLE_RM_GARCH['DCC']), annot=True, cmap='coolwarm', fmt=".2f", cbar=True, 
            xticklabels=labels, yticklabels=labels)
plt.xticks(rotation=80)



%%capture
import pandas as pd
import numpy as np
import rpy2.robjects as ro
from rpy2.robjects import pandas2ri

date_range = pd.date_range(start="2023-01-01", end=pd.Timestamp.today(), freq="D")

np.random.seed(42)
df = pd.DataFrame({
    "Prezzo": np.random.randn(len(date_range)) * 10 + 100,
    "ADJUSTED_CLOSE": np.random.randn(len(date_range)) * 5 + 50,
}, index=date_range)

df_log_ret = np.log(df / df.shift(1)) * 100
df_log_ret = injector.get_multi_index()

if df_log_ret.shape[1] == 1:
    df_log_ret['log_ret_2'] = df_log_ret.iloc[:, 0]


pandas2ri.activate()
r_rets = ro.conversion.py2rpy(df_log_ret)
r_rets = ro.r('as.matrix')(r_rets) 

r_dccgarch_code = """
                library('rmgarch')
                function(r_rets, n_days){
                        r_rets <- as.matrix(r_rets)
                        n <- dim(r_rets)[2]

                        if (n < 2) stop("Errore: DCC-GARCH richiede almeno due serie temporali.")  

                        univariate_spec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),
                                                    variance.model = list(garchOrder = c(1,1),
                                                                        variance.targeting = FALSE, 
                                                                        model = "sGARCH"),
                                                    distribution.model = "norm")
                        
                        dcc_spec <- dccspec(uspec = multispec(replicate(n, univariate_spec)),
                                            dccOrder = c(1,1),
                                            distribution = "mvlaplace")
                        
                        dcc_fit <- dccfit(dcc_spec, data=r_rets)
                        forecasts <- dccforecast(dcc_fit, n.ahead = n_days)
                        list(dcc_fit, forecasts@mforecast$H)
                }
                """

r_dccgarch = ro.r(r_dccgarch_code)
r_res = r_dccgarch(r_rets, 20) 
pandas2ri.deactivate()

r_dccgarch_model = r_res[0]
r_forecast_cov = r_res[1]

n_cols = df_log_ret.shape[1]
n_elements = n_cols * n_cols
n_matrix = len(r_forecast_cov[0]) // n_elements

cov_matrix = np.zeros((n_cols, n_cols))
for i in range(n_matrix):
    i_matrix = np.array(r_forecast_cov[0][i * n_elements:(i + 1) * n_elements])
    i_matrix = i_matrix.reshape(n_cols, n_cols)
    cov_matrix += i_matrix

print("Numero di matrici previste:", n_matrix)
print("Matrice di covarianza sommata:\n", cov_matrix)


%%capture
!jupyter nbconvert --to html --no-input project.ipynb




